---
title: "Nomilo Fishpond Biogoechemical Analysis"
execute: 
  warning: false
  message: false
code-annotations: hover
code-overflow: wrap
format: 
  html:
    toc-title: "Data Analysis Workflow:"
    toc-location: left
---

::: {.callout-note title="Interactive Code"}
Throughout this document, hover over the numbered annotations to the right of code chunks to reveal detailed explanations and comments about the code. Where drop-down *italicized* text is present, expand by pressing
on arrow to see code.
:::

## Install Packages

```{r}
#| label: install-packages
#| eval: false
install.packages(c("rio", "tidyverse", "janitor", "lubridate", "rmarkdown", "fs"))
```

## Load Libraries

```{r}
#| label: load-libraries

library(rio) # <1>
library(tidyverse) # <2>
library(janitor) # <3>
library(lubridate) # <4>
library(rmarkdown) # <5>
library(fs) # <6>
```

1. For importing excel data
2. For cleaning of data 
3. For cleaning variable names
4. For cleaning dates
5. For displaying tables
6. For file path usage

## Import Raw Data

### Procedure

Define vector of files to import: 

```{r}
#| label: create-vector-file-paths
files_to_import <- dir_ls(path = "data/raw") # <1>

for (i in seq_along(files_to_import)) { # <2>
  cat(i, "= ", files_to_import[i], "\n") # <2>
} # <2>
```

1. Store the file paths of our raw data within the `data/raw` directory in `files_to_import`
2. Print each file path with its index

Use the `purrr::map()` function to iteratively import files in the `files_to_import` vector 
except for the profiles data and .RData files: 

::: {.callout-caution title="@iteratively-import-raw-data Code Chunk Execution Warning"}
The @iteratively-import-raw-data code chunk should only be ran once when raw data is updated
because it takes long to execute. Therefore, run the @efficiently-load-raw-data code chunk
instead to easily import up-to-date raw data.
:::

```{r}
#| label: iteratively-import-raw-data
#| messages: false
#| warnings: false
#| eval: false
dfs_no_profiles <- map(files_to_import[c(2:4, 6, 7)], import_list) # <1>
current_date <- format(Sys.Date(), "%Y-%m-%d")
save(dfs_no_profiles, file = paste0("data/raw/", current_date, "_dfs-no-profiles.RData")) # <1>
```

Efficiently import up-to-date raw data:

```{r}
#| label: efficiently-load-raw-data
load(files_to_import[8])
```

Rename datasets:

We will always use snakecase when naming our data objects and functions (e.g., `data_object_name` or `function_name()`).

```{r}
#| label: rename-raw-datasets
names(dfs_no_profiles) <- gsub("data/raw/2024-02-28_|\\.xlsx$|\\.xls$", "", 
                               files_to_import[c(2:4, 6, 7)]) # <1>
names(dfs_no_profiles) <- gsub("-", "_", names(dfs_no_profiles)) # <2>
names(dfs_no_profiles) # <3>
```

1. Remove prefixes and file extensions
2. Replace hyphens with underscores
3. Check if names were outputted correctly

Rename each sheet within each raw dataset to be lowercased and replace spaces with underscores:

```{r}
#| label: rename-sheets-within-each-raw-dataset
dfs_no_profiles <- map(dfs_no_profiles, ~ set_names(.x, gsub(" ", "_", tolower(names(.x)))))
```

Create separate datasets by specifying the Excel sheet from each spreadsheet we want to tidy:

```{r}
#| label: create-separate-datasets
ksf_clam_growth_data <- dfs_no_profiles$ksf_clam_growth$sheet1
ksf_compiled_data <- dfs_no_profiles$ksf_compiled_data$full_data
ksf_oyster_cylinder_growth_data <- dfs_no_profiles$ksf_oyster_cylinder_growth$sheet1
water_samples_data <- dfs_no_profiles$water_samples$data_overview
weather_data <- dfs_no_profiles$weather_data$weather_ksf
```

We want to combine multiple sheets within the profiles Excel spreadsheet into one, therefore,
we will import it separately:

```{r}
#| label: import-raw-profiles-data
sheets_to_import <- c("L1", "L2", "L3", "L4") # <1>

profiles_data <- profiles_data <- map_dfr(sheets_to_import, function(sheet_name) { # <2>
  import(files_to_import[5], which = sheet_name) # <2>
}) %>%  # <2>
  bind_rows() # <3>
```

1. [code annotation]
2. [code annotation]
3. [code annotation]

### View Raw Data

::: {.panel-tabset}

#### ksf_clam_growth_data

```{r}
#| echo: false
paged_table(ksf_clam_growth_data)
```

#### ksf_compiled_data

```{r}
#| echo: false
paged_table(ksf_compiled_data)
```

#### ksf_oyster_cylinder_growth_data

```{r}
#| echo: false
paged_table(ksf_oyster_cylinder_growth_data)
```

#### water_samples_data

```{r}
#| echo: false
paged_table(water_samples_data)
```

#### weather_data

```{r}
#| echo: false
paged_table(weather_data)
```

#### profiles_data

```{r}
#| echo: false
paged_table(profiles_data)
```

:::

## Tidy Raw Data

### Tidying Processes

::: {.panel-tabset}

#### ksf_clam_growth_data_tidied

```{r}
#| label: tidy-ksf-clam-growth-data-dataset
#| code-fold: true
#| code-summary: <i>Steps to clean data</i>
new_var_names <- c(
  "sort_date", "color", "clams_in_count", "clams_in_lbs", "clams_in_avg_per_lb", 
  "clams_out_count", "clams_out_lbs", "clams_out_avg_per_lb", "growth_in_lbs",
  "growth_pct", "sr", "days_btwn_sort"
  )

new_date_col <- c(
  "2023-10-17", "2023-12-06", "2023-12-12", "2024-01-02", "2024-01-10", "2024-01-24", 
  "2024-01-31", "2024-02-08", "2024-02-13"
  ) 

ksf_clam_growth_data_tidied <- ksf_clam_growth_data %>%
  slice(-1) %>%
  setNames(new_var_names) %>%
  mutate(date = as.Date(new_date_col)) %>% 
  dplyr::select(-sort_date) %>% 
   pivot_longer(
    cols = c(
      clams_in_count, clams_in_lbs, clams_in_avg_per_lb, clams_out_count, 
      clams_out_lbs, clams_out_avg_per_lb
      ),
    names_to = c("stage", ".value"),
    names_prefix = "clams_", 
    names_sep = "_", 
    values_to = "value"
  ) %>%
  mutate(stage = if_else(str_detect(stage, "in"), "In", "Out")) %>%
  rename(avg_per_lbs = avg) %>% 
  mutate(across(c(color, stage), as.factor)) %>%
  mutate(across(c(count, lbs, avg_per_lbs, growth_in_lbs, growth_pct, sr), 
                ~as.numeric(gsub("%", "", .)))) %>% 
  arrange(date, color, stage) %>% 
  dplyr::select(date, days_btwn_sort, color, stage, count, lbs, avg_per_lbs, 
                growth_in_lbs, growth_pct, sr)

paged_table(ksf_clam_growth_data_tidied)
```

1.
2.
3.
4.
5.
6.

#### ksf_compiled_data_tidied

```{r}
#| label: tidy-ksf-compiled-data-dataset
#| code-fold: true
#| code-summary: <i>Steps to clean data</i>
ksf_compiled_data_tidied <- ksf_compiled_data %>% 
  rename_with(~gsub("\\s*\\([^\\)]+\\)", "", .x)) %>% # <1>
  janitor::clean_names() %>% # <1>
  rename(date = date_time) %>%  # <2>
  mutate(date = as.Date(date)) %>% # <2>
  filter(date >= as.Date("2023-11-20") & date <= as.Date("2024-02-20")) %>% # <2>
  arrange(date) %>%  # <2>
  dplyr::select(-c(external_voltage, wk_num, wind_dir, # <3>
                   spadd, outdoor_temperature, hourly_rain, # <3>
                   solar_radiation, resistivity, battery_capacity, # <3>
                   hour, daynum, data_pt, wind_sp, diradd, # <3>
                   wind_speed, wind_direction, tide, day, month, year) # <3>
                ) %>% # <3>
  dplyr::select(where(~ !anyNA(.))) %>%  # <4>
  group_by(date) %>% # <5>
  summarise(across(where(is.numeric), \(x) mean(x, na.rm = TRUE))) # <5>

paged_table(ksf_compiled_data_tidied)
```

1. Clean variable names by removing everything in parentheses, using lowercase 
and underscores in place of spaces
2. Rename the `date_time` variable to `date`, filter to desired date range and 
sort by `date`
3. Remove unnecessary variables
4. Remove columns with containing all NA values
5. Group by `date` and calculate the average of every variable for each day

#### ksf_oyster_cylinder_growth_data_tidied

```{r}
#| label: tidy-ksf-oyster-cylinder-growth-data-dataset
#| code-fold: true
#| code-summary: <i>Steps to clean data</i>

oyster_var_names <- c(
  "date", "oyster_large_weight", "oyster_large_gain", "oyster_small_weight",
  "oyster_small_gain", "oyster_chlorophyll"
  ) #<1>

ksf_oyster_cylinder_growth_data_tidied <- ksf_oyster_cylinder_growth_data %>% 
  dplyr::select(c(1, 4, 5, 8, 9, 12)) %>% #<2> 
  slice(-1) %>% #<2>
  setNames(oyster_var_names) %>% #<1>
  pivot_longer( #<3>
    cols = c(oyster_large_weight, oyster_large_gain, #<3>
             oyster_small_gain, #<3>
             oyster_small_weight), #<3>
    names_to = c("oyster_size", ".value"), #<3>
    names_prefix = "oyster_", #<3>
    names_sep = "_", #<3>
    values_to = "value" #<3>
  ) %>% #<3>
  mutate(oyster_size = if_else(str_detect(oyster_size, "small"), "Small", "Large")) %>% #<4>
  mutate(oyster_size = as.factor(oyster_size), #<5>
         across(c(weight, gain), as.numeric) #<5>
        ) %>% #<5>
  filter(date >= as.Date("2023-11-20") & date <= #<6>
           as.Date("2024-02-14")) #<6>

paged_table(ksf_oyster_cylinder_growth_data_tidied)
```

1. Manually set variable names
2. Select desired columns and remove first row
3. Convert from wide to long format
4. Create a new variable that differentiates oyster size
5. Adjust data types to numeric and factor
6. Filter to desired date range

*Address the NA values before merge*

#### water_samples_data_tidied

```{r}
#| label: tidy-water-samples-data-dataset
#| code-fold: true
#| code-summary: <i>Steps to clean data</i>
water_samples_data_tidied <- water_samples_data %>%
  slice(-c(44:52)) %>% 
  rename_with(~gsub("\\s*\\([^\\)]+\\)", "", .x)) %>% # <1>
  janitor::clean_names() %>% # <1>
  mutate(
    date = if_else(date == "44074", 
                   as.character(as.Date("2024-01-09")),
                   format(dmy(date), "%Y-%m-%d")) 
  )

paged_table(water_samples_data_tidied)
```

Done: 
- Date format
- Date number conversion

The reason why it wasn't working was because the date column was of a character
data type, therefore we can easily convert 44074 but we were assuming that R knew
the other dates were of a date type. So to fix this, we first needed to convert it 
into a date in the original format of DD-MM-YYYY, then convert it to our desired format
of YYYY-MM-DD.

Need to do:
- Names clean up
- Add numbers to sample ID

#### weather_data_tidied

```{r}
#| label: tidy-weather-data-dataset
#| code-fold: true
#| code-summary: <i>Steps to clean data</i>
weather_data_tidied <- weather_data

paged_table(weather_data_tidied)
```

#### profile_data_tidied

```{r}
#| label: tidy-profile-data-dataset
#| code-fold: true
#| code-summary: <i>Steps to clean data</i>
profiles_data_tidied <- profiles_data

paged_table(profiles_data_tidied)
```

::: 

### Merge Tidied Datasets

### Export Tidied Datasets

Export tidied datasets to CSV into `data/tidied` folder:

```{r}
#| label: export-tidied-datasets
#| eval: false
source("code/functions/export_to_csv.R")

dfs_to_export <- list( # <1>
  ksf_clam_growth_data_tidied = ksf_clam_growth_data_tidied, # <1>
  ksf_compiled_data_tidied = ksf_compiled_data_tidied, # <1>
  ksf_oyster_cylinder_growth_data_tidied = ksf_oyster_cylinder_growth_data_tidied # <1>
) # <1>

imap(dfs_to_export, ~ export_to_csv(.x, .y, "data/tidied")) # <2>
```

1. List of dataframes we want to export as CSV files
2. Iterate the `export_to_csv(df, df_name, dir_path)` function over each dataframe. 
`.x` refers to the dataframe. `.y` refers to the name of the dataframe. These are 
passed to `export_to_csv()` function along with the desired directory path.


Export merged final data set into `data/outputs` folder.

## Data Dictionary

## Exploratory Data Analysis

## Correlational Analysis