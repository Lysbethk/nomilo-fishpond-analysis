---
title: "Nomilo Fishpond Biogoechemical Analysis"
author: "Lysbeth Koster"
date: "02/28/2024"
execute: 
  warning: false
  message: false
code-annotations: hover
code-overflow: wrap
format: 
  html:
    toc-title: "Data Analysis Workflow:"
    toc-location: left
---

## Introduction

[Explain the purpose of this website]

### Research Questions

1. How do changes in the Nomilo fishpond over time correlate with 

::: {.callout-note title="Interactive Code"}
Throughout this document, hover over the numbered annotations to the right of code chunks to reveal detailed explanations and comments about the code. Where drop-down *italicized* text is present, expand by pressing
on arrow to see code.
:::

## Install Packages

```{r}
#| label: install-packages
packages <- c("rio", "tidyverse", "janitor", "lubridate", "rmarkdown", "fs", "hms", "zoo", "corrplot", "kableExtra",
              "psych", "ggplot2")


for (pkg in packages) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg)
  }
}
```

## Load Libraries

```{r}
#| label: load-libraries

library(rio) # <1>
library(tidyverse) # <2>
library(janitor) # <3>
library(lubridate) # <4>
library(rmarkdown) # <5>
library(fs) # <6>
library(hms)
library(zoo)
library(corrplot)
library(kableExtra)
library(psych)
library(ggplot2)
```

1. For importing excel data
2. For cleaning of data 
3. For cleaning variable names
4. For cleaning dates
5. For displaying tables
6. For file path usage

## Import Raw Data

### Procedure

Define vector of files to import: 

```{r}
#| label: create-vector-file-paths
files_to_import <- dir_ls(path = "data/raw") # <1>

for (i in seq_along(files_to_import)) { # <2>
  cat(i, "= ", files_to_import[i], "\n") # <2>
} # <2>
```

1. Store the file paths of our raw data within the `data/raw` directory in `files_to_import`
2. Print each file path with its index

Use the `purrr::map()` function to iteratively import files in the `files_to_import` vector 
except for the profiles data and .RData files: 

::: {.callout-caution title="@iteratively-import-raw-data Code Chunk Execution Warning"}
The @iteratively-import-raw-data code chunk should only be ran once when raw data is updated
because it takes long to execute. Therefore, run the @efficiently-load-raw-data code chunk
instead to easily import up-to-date raw data.
:::

```{r}
#| label: iteratively-import-raw-data
#| messages: false
#| warnings: false
#| eval: false
dfs_no_profiles <- map(files_to_import[c(2:4, 6, 7)], import_list) # <1>
current_date <- format(Sys.Date(), "%Y-%m-%d")
save(dfs_no_profiles, file = paste0("data/raw/", current_date, "_dfs-no-profiles.RData")) # <1>
```

::: {.callout-warning title="Ensure the Correct Index Value is Inputted Below"}
Refer to the output of the `files_to_import` data object to ensure you are inputting the correct
index value corresponding to the file path that needs to be loaded.
:::

Efficiently import up-to-date raw data:

```{r}
#| label: efficiently-load-raw-data
load(files_to_import[10])
```

Rename datasets:

We will always use snakecase when naming our data objects and functions (e.g., `data_object_name` or `function_name()`).

```{r}
#| label: rename-raw-datasets
names(dfs_no_profiles) <- gsub("data/raw/2024-02-28_|\\.xlsx$|\\.xls$", "", 
                               files_to_import[c(2:4, 6, 7)]) # <1>
names(dfs_no_profiles) <- gsub("-", "_", names(dfs_no_profiles)) # <2>
names(dfs_no_profiles) # <3>
```

1. Remove prefixes and file extensions
2. Replace hyphens with underscores
3. Check if names were outputted correctly

Rename each sheet within each raw dataset to be lowercased and replace spaces with underscores:

```{r}
#| label: rename-sheets-within-each-raw-dataset
dfs_no_profiles <- map(dfs_no_profiles, ~ set_names(.x, gsub(" ", "_", tolower(names(.x)))))
```

Create separate datasets by specifying the Excel sheet from each spreadsheet we want to tidy:

```{r}
#| label: create-separate-datasets
ksf_clams_growth_data <- dfs_no_profiles$ksf_clam_growth$sheet1
ksf_compiled_data <- dfs_no_profiles$ksf_compiled_data$full_data
ksf_oyster_cylinder_growth_data <- dfs_no_profiles$ksf_oyster_cylinder_growth$sheet1
water_samples_data <- dfs_no_profiles$water_samples$data_overview
weather_data <- dfs_no_profiles$weather_data$weather_ksf
tidal_data <- dfs_no_profiles$ksf_compiled_data$tides
```

We want to combine multiple sheets within the profiles Excel spreadsheet into one, therefore,
we will import it separately:

```{r}
#| label: import-raw-profiles-data
sheets_to_import <- c("L1", "L2", "L3", "L4") # <1>

profiles_data <- profiles_data <- map_dfr(sheets_to_import, function(sheet_name) { # <2>
  import(files_to_import[5], which = sheet_name) # <2>
}) %>%  # <2>
  bind_rows() # <3>
```

1. [code annotation]
2. [code annotation]
3. [code annotation]

### View Raw Data

::: {.panel-tabset}

#### ksf_clams_growth_data

```{r}
#| echo: false
paged_table(ksf_clams_growth_data)
```

#### ksf_compiled_data

```{r}
#| echo: false
paged_table(ksf_compiled_data)
```

#### ksf_oyster_cylinder_growth_data

```{r}
#| echo: false
paged_table(ksf_oyster_cylinder_growth_data)
```

#### water_samples_data

```{r}
#| echo: false
paged_table(water_samples_data)
```

#### weather_data

```{r}
#| echo: false
paged_table(weather_data)
```

#### profiles_data

```{r}
#| echo: false
paged_table(profiles_data)
```

#### tidal_data

```{r}
#| echo: false
paged_table(tidal_data)
```

:::

## Tidy Raw Data

### Tidying Processes

::: {.panel-tabset}

#### ksf_clams_growth_data_tidied

```{r}
#| label: tidy-ksf-clam-growth-data-dataset
#| code-fold: true
#| code-summary: <i>Steps to clean data</i>
new_clam_var_names <- c( #<1>
  "sort_date", "color", "clams_in_count", "clams_in_lbs",  "clams_in_avg_per_lb",
  "clams_out_count", "clams_out_lbs", "clams_out_avg_per_lb", "growth_in_lbs", 
  "growth_pct", "sr", "days_btwn_sort" #<1>
  ) #<1>

new_clam_date_col <- c( #<2>
  "2023-10-17", "2023-12-06", "2023-12-12", "2024-01-02",  "2024-01-10", "2024-01-24",
  "2024-01-31", "2024-02-08", "2024-02-13" #<2>
  ) #<2>

ksf_clams_growth_data_tidied <- ksf_clams_growth_data %>%
  slice(-1) %>% #<3>
  setNames(new_clam_var_names) %>% #<4>
  mutate(date = as.Date(new_clam_date_col)) %>% #<4>
  dplyr::select(-sort_date) %>% #<4>
   pivot_longer( #<4>
    cols = c( #<4>
      clams_in_count, clams_in_lbs, clams_in_avg_per_lb,   clams_out_count, 
      clams_out_lbs, clams_out_avg_per_lb #<4>
      ), #<4>
    names_to = c("stage", ".value"), #<4>
    names_prefix = "clams_", #<4>
    names_sep = "_", #<4>
    values_to = "value" #<4>
  ) %>% #<4>
  mutate(stage = if_else(str_detect(stage, "in"), "In", "Out")) %>% #<5>
  rename(avg_per_lbs = avg) %>% #<6>
  mutate(across(c(color, stage), as.factor)) %>% #<7>
  mutate(across(c(count, lbs, avg_per_lbs, growth_in_lbs, growth_pct, sr), #<8>
                ~as.numeric(gsub("%", "", .)))) %>% #<8>
  arrange(date, color, stage) %>% #<9>
  dplyr::select(date, days_btwn_sort, color, stage, count, lbs, avg_per_lbs, #<9>
                growth_in_lbs, growth_pct, sr) %>%  #<9>
  rename("days_btwn_clams_sort" = days_btwn_sort,
         "clams_color" = color,
         "clams_stage" = stage,
         "clams_count" = count,
         "weight" = lbs,
         "avg_weight" = avg_per_lbs,
         "clams_growth" = growth_in_lbs,
         "clams_sr" = sr)
         

paged_table(ksf_clams_growth_data_tidied)
```

1. Manually set variable names
2. Assign dates to new date column
3. Delete first row
4. Set date as correct variable type and pivot data set based on date range.
5. Assign In and Out to stage
6. Rename variable of average to average per lbs
7. Set stage and color as factor variable types
8. Set variables as numeric variable types
9. Arrange values by date, color, and stage 

#### ksf_compiled_data_tidied

```{r}
#| label: tidy-ksf-compiled-data-dataset
#| code-fold: true
#| code-summary: <i>Steps to clean data</i>
ksf_compiled_data_tidied <- ksf_compiled_data %>% 
  rename_with(~gsub("\\s*\\([^\\)]+\\)", "", .x)) %>% # <1>
  janitor::clean_names() %>% # <1>
  rename(date = date_time) %>%  # <2>
  mutate(date = as.Date(date)) %>% # <2>
  filter(date >= as.Date("2023-11-20") & date <= as.Date("2024-02-20")) %>% # <2>
  arrange(date) %>%  # <2>
  dplyr::select(-c(external_voltage, wk_num, wind_dir, # <3>
                   spadd, outdoor_temperature, hourly_rain, # <3>
                   solar_radiation, resistivity, battery_capacity, # <3>
                   hour, daynum, data_pt, wind_sp, diradd, # <3>
                   wind_speed, wind_direction, tide, day, month, year) # <3>
                ) %>% # <3>
  dplyr::select(where(~ !anyNA(.))) %>%  # <4>
  group_by(date) %>% # <5>
  summarise(across(where(is.numeric), \(x) mean(x, na.rm = TRUE))) %>% # <5>
  rename("ksf_salinity" = salinity,
         "ksf_rdo_saturation" = rdo_saturation,
         "ksf_rdo_concentration" = rdo_concentration,
         "ksf_actual_conductivity" = actual_conductivity,
         "ksf_total_dissolved_solids" = total_dissolved_solids,
         "ksf_ammonium" = ammonium,
         "ksf_barometric_pressure" = barometric_pressure,
         "ksf_oxygen_partial_pressure" = oxygen_partial_pressure,
         "ksf_specific_conductivity" = specific_conductivity,
         "ksf_density" = density,
         "ksf_chlorophyll_a_fluorescence" = chlorophyll_a_fluorescence,
         "ksf_ammonium_m_v" = ammonium_m_v)

paged_table(ksf_compiled_data_tidied)
```

1. Clean variable names by removing everything in parentheses, using lowercase and underscores in place of spaces
2. Rename the `date_time` variable to `date`, filter to desired date range and 
sort by `date`
3. Remove unnecessary variables
4. Remove columns with containing all NA values
5. Group by `date` and calculate the average of every variable for each day

#### ksf_oyster_cylinder_growth_data_tidied

```{r}
#| label: tidy-ksf-oyster-cylinder-growth-data-dataset
#| code-fold: true
#| code-summary: <i>Steps to clean data</i>

oyster_var_names <- c(
  "date", "oyster_large_weight", "oyster_large_gain", "oyster_small_weight",
  "oyster_small_gain", "oyster_chlorophyll"
  ) #<1>

ksf_oyster_cylinder_growth_data_tidied <- ksf_oyster_cylinder_growth_data %>% 
  dplyr::select(c(1, 4, 5, 8, 9, 12)) %>% #<2> 
  slice(-1) %>% #<2>
  setNames(oyster_var_names) %>% #<1>
  pivot_longer( #<3>
    cols = c(oyster_large_weight, oyster_large_gain, #<3>
             oyster_small_gain, #<3>
             oyster_small_weight), #<3>
    names_to = c("oyster_size", ".value"), #<3>
    names_prefix = "oyster_", #<3>
    names_sep = "_", #<3>
    values_to = "value" #<3>
  ) %>% #<3>
  mutate(oyster_size = if_else(str_detect(oyster_size, "small"), "Small", "Large")) %>% #<4>
  mutate(date = as.Date(date), #<5>
         oyster_size = as.factor(oyster_size), #<5>
         across(c(weight, gain), as.numeric) #<5>
        ) %>% #<5>
  filter(date >= as.Date("2023-11-20") & date <= #<6>
           as.Date("2024-02-14")) %>%  #<6>
  mutate(weight = weight * 0.00220462) %>% 
  rename("growth_pct" = gain)

paged_table(ksf_oyster_cylinder_growth_data_tidied)
```

1. Manually set variable names
2. Select desired columns and remove first row
3. Convert from wide to long format
4. Create a new variable that differentiates oyster size
5. Adjust data types to numeric and factor
6. Filter to desired date range

#### water_samples_data_tidied

```{r}
#| label: tidy-water-samples-data-dataset
#| code-fold: true
#| code-summary: <i>Steps to clean data</i>

water_samples_data_tidied <- water_samples_data %>%
  slice(-c(44:52)) %>% 
  rename_with(~gsub("\\s*\\([^\\)]+\\)", "", .x)) %>% # <1>
  janitor::clean_names() %>% # <1>
  mutate( # <2>
    date = if_else(date == "44074", # <2>
            as.character(as.Date("2024-01-09")), # <2>
            format(dmy(date), "%Y-%m-%d")) # <2>
  ) %>% # <2>
  mutate(sample_id = 1:nrow(.)) %>% # <3>
  mutate(date = as.Date(date), # <4>
         across(c(nomilo_id, location, round, depth), as.factor)) %>% # <4>
  select(-c(sample_id, nomilo_id, tube_name))

paged_table(water_samples_data_tidied)
```

1. Clean variable names by removing everything in parentheses, using lowercase and underscores in place of spaces
2. Replaces incorrect date values and format as YYYY-MM-DD
3. Add values for sample ID
4. Set correct variable types

#### weather_data_tidied

```{r}
#| label: tidy-weather-data-dataset
#| code-fold: true
#| code-summary: <i>Steps to clean data</i>
weather_data_tidied <- weather_data %>% 

janitor::clean_names() %>%  #<1>
   unite(date, year, month, day, sep = "-") %>% #<2>
  mutate(date = ymd(date)) %>% #<2>
   select(-c(1, 3)) %>% #<3>
  rename("outdoor_temperature" = outdoor_temp_f) %>% #<4>
   mutate(outdoor_temperature = (outdoor_temperature - 32) * (5/9)) %>% #<4>
  group_by(date) %>% #<5>
  summarise(across(where(is.numeric), \(x) mean(x, na.rm = TRUE))) %>% #<5>
  slice(-1) #<6>

paged_table(weather_data_tidied)
```

1. Clean variable names
2. Merge separate day, month, year columns into one column variable and format as YYYY-MM-DD.
3. Cut columns
4. Rename outdoor temperature and convert from Fahrenheit to Celcius
5. Group by date and then take average values per day
6. Cut first row

#### profiles_data_tidied

```{r}
#| label: tidy-profile-data-dataset
#| code-fold: true
#| code-summary: <i>Steps to clean data</i>

new_profile_var_names <- c("depth", "water_temperature", "dissolved_oxygen", "salinity", "conductivity", "visibility", "location", "date") #<1>

profiles_data_tidied <- profiles_data %>% #<2>
  select(-c(6, 8)) %>% #<2>
  mutate( #<3>
    temp_column1 = NA_character_,  #<3> 
    temp_column2 = NA_character_  #<3>
  ) %>%
  setNames(new_profile_var_names) %>% #<4> 
  mutate( #<5>
    location = ifelse(depth == "Location", water_temperature, NA_character_), 
    date = ifelse(depth == "Date",  water_temperature, NA_character_) #<5> 
  ) %>%
  fill(location, date, .direction = "down") %>% #<6>
  filter(depth != "Location", depth != "Date") %>% #<7>  
  mutate( #<8>
    location = case_when( #<8>
      location == "L1 Northwest buoy" ~ "back buoy",
      location == "L2 Middle Buoy" ~ "mid buoy",
      location == "L3 Production Dock" ~ "production dock", #<8>
      location == "L4 Auwai" ~ "auwei", #<8>
      TRUE ~ location #<8>
    ), #<8>
    date = case_when( #<8>
      date %in% c("45258", "2023-11-28") ~ "2023-11-28", #<8>
      date %in% c("45282", "2023-12-21") ~ "2023-12-21", #<8>
      date %in% c("45536", "2024-01-09") ~ "2024-01-09", #<8>
      date %in% c("30/1/24", "30/01/24") ~ "2024-01-30", #<8>
      date %in% c("20/02/24", "20/2/24") ~ "2024-02-20", #<8>
      TRUE ~ date #<8>
    )) %>% #<8>
  mutate( #<8>
    date = as.Date(date, format = "%Y-%m-%d"), #<8> 
    conductivity = case_when( #<9> 
      row_number() %in% c(1:11) ~ NA_character_, #<9> 
      TRUE ~ as.character(conductivity) #<9>
    ) #<9>
  ) %>% #<9>
  filter(!(depth %in% c("Samples", "Depth"))) %>% #<10> 
  mutate(date = as.Date(date), #<11> 
         across(c(depth, location), as.factor),
         across(c(water_temperature,  dissolved_oxygen, salinity, 
                  conductivity,visibility),  as.numeric)) %>% #<11>
   fill(visibility, .direction = "down") %>% #<12>
  mutate(visibility = if_else(date == "2023-11-28",  NA_real_, visibility)) #<13>

paged_table(profiles_data_tidied)
```

1. Set new variable names manually
2. Delete unnecessary columns
3. Temporarily create two new columns to replace the ones we deleted
4. Assign new profile variable names to rename variables in data set
5. Takes location from one column of location and date data, and assigns it to corresponding data of another column.
6. Fill values of temperature downwards in newly created date and location column.
7. Gets rid of the 'location' and 'date' rows that had empty values.
8. Renames values
9. Removes turbidity data rows 1:11
10. Looks for rows containing samples and depth names and negate these values.
11. Sets correct data types for each variable
12. Fills  values from the temperature downwards into the newly created columns for date and location

#### tidal_data_tidied

```{r}
#| label: tidy-tidal-data-dataset
#| code-fold: true
#| code-summary: <i>Steps to clean data</i>

tidal_data_tidied <- tidal_data %>% 

janitor::clean_names() %>% #<1>
  mutate(date = as.Date(date, format = "%Y-%m-%d"))  %>% #<2>
   filter(date >= as.Date("2023-11-20") & date <=  as.Date("2024-02-20")) %>% #<3>
  select(-2) %>% #<4>
  mutate(time = as_hms(format(time, "%H:%M:%S")), #<5>
         high_low = as.factor(high_low)) #<6>
  
paged_table(tidal_data_tidied)
```

1. Clean variable names 
2. Set date as correct variable type and format YYYY-MM-DD
3. Filter to desired date range
4. Cut column
5. Set time as time variable type
6. Set variable as factor type

::: 

### Merge and Impute Tidied Datasets

::: {.panel-tabset}

#### Biogeochemical & Physical Variables

```{r}
# Merging
profiles_water_samples_merged <- reduce(list(profiles_data_tidied, water_samples_data_tidied), full_join, by = c("date", "location", "depth")) %>% 
  relocate(date, round, location, depth, .before = water_temperature) %>%
  arrange(date) %>% 
  fill(round, .direction = "down") %>%
  mutate(round = if_else(is.na(round), "1", round),
         round = as.factor(round))
```

```{r}
# Complete dataset
compiled_weather_merged <- reduce(list(ksf_compiled_data_tidied, weather_data_tidied), full_join, by = "date")

biogeochem_vars_merged <- full_join(compiled_weather_merged, profiles_water_samples_merged)
```

```{r}
# Interpolating
biogeochem_vars_interp <- biogeochem_vars_merged %>% 
  # Selects numeric columns with missing values, linearly interpolates NAs by 
  # drawing straight lines between existing points, and extends the outermost 
  # values to fill NAs at the start or end
  mutate(across(where(~is.numeric(.x) && any(is.na(.x))),
                ~na.approx(.x, na.rm = FALSE, rule = 2)))
```

```{r}
paged_table(biogeochem_vars_interp)
```

#### Clams

```{r}
#| code-summary: Clams Growth Merged with Environmental Variables
#| code-fold: true

# Merging
clams_growth_biogeochem_vars_merged <- full_join(ksf_clams_growth_data_tidied, biogeochem_vars_interp, by = "date")

# Interpolating -- other option is to aggregate to weekly or monthly, but dates 
# are very mismatched to aggregate to monthly and dataset would be very small if 
# aggregated to monthly
clams_growth_biogeochem_vars_interp <- clams_growth_biogeochem_vars_merged %>% 
 mutate(across(
    .cols = setdiff(names(.)[sapply(., function(col) is.numeric(col) &&
                                      any(is.na(col)))], "days_btwn_clams_sort"),
    .fns = ~na.approx(.x, na.rm = FALSE, rule = 2)
  )) %>%
  relocate(date, round, location, depth, clams_color, clams_stage, .before = days_btwn_clams_sort) %>% 
  arrange(date)
```

#### Oysters

```{r}
#| code-summary: Oyster Growth Interpolated and Merged with Environmental Variables
#| code-fold: true

oyster_growth_biogeochem_vars_merged <- full_join(ksf_oyster_cylinder_growth_data_tidied, biogeochem_vars_interp, by = "date")

# Interpolating -- other option is to aggregate to weekly or monthly, but dates 
# are very mismatched to aggregate to monthly and dataset would be very small if 
# aggregated to monthly

oyster_growth_biogeochem_vars_interp <- oyster_growth_biogeochem_vars_merged %>% 
 mutate(across(where(~is.numeric(.x) && any(is.na(.x))),
                ~na.approx(.x, na.rm = FALSE, rule = 2))) %>% 
 # relocate(date, round, location, depth, clams_color, clams_stage, .before = days_btwn_clams_sort) %>% 
  arrange(date)

```

:::

## Processed Datasets

### Export Tidied Datasets

Export tidied datasets to CSV into `data/tidied` folder:

```{r}
#| label: export-tidied-datasets
#| eval: false
source("code/functions/export_to_csv.R")

dfs_to_export <- list( # <1>
  ksf_clams_growth_data_tidied = ksf_clams_growth_data_tidied, # <1>
  ksf_compiled_data_tidied = ksf_compiled_data_tidied, # <1>
  ksf_oyster_cylinder_growth_data_tidied = ksf_oyster_cylinder_growth_data_tidied, # <1>
  water_samples_data_tidied = water_samples_data_tidied, # <1>
  profiles_data_tidied = profiles_data_tidied # <1>
) # <1>

imap(dfs_to_export, ~ export_to_csv(.x, .y, "data/tidied")) # <2>
```

1. List of dataframes we want to export as CSV files
2. Iterate the `export_to_csv(df, df_name, dir_path)` function over each dataframe. 
`.x` refers to the dataframe. `.y` refers to the name of the dataframe. These are 
passed to `export_to_csv()` function along with the desired directory path.

Export merged final data set into `data/outputs` folder.

### Data Dictionaries

## Exploratory Data Analysis
### Profiles
How is [salinity, dissolved oxygen, conductivity] distributed over the pond?

Get a visual per Location of how [variable] changes with depth over time

```{r}
# Assuming profiles_data_tidied is your dataset
ggplot(profiles_data_tidied, aes(x = date, y = conductivity, color = as.numeric(as.character(depth)))) +
  geom_point(size = 3, alpha = 0.8) + # Larger points with slight transparency
  geom_line(size = 1, alpha = 0.8) + # Thicker lines with slight transparency
  labs(x = "Date", y = "Conductivity", title = "Conductivity Change Over Time") +
  theme_minimal() +
  facet_wrap(~location) +
  scale_color_gradient(low = "blue", high = "red", name = "Depth") +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust = 1),
        axis.title.x = element_text(margin = margin(t = 10), face = "bold"),
        plot.title = element_text(hjust = 0.5, face = "bold"),
        axis.title.y = element_text(face = "bold"),
        legend.title = element_text(face = "bold")) +
  ylim(35, 55)
```

How is [salinity, dissolved oxygen, conductivity] distributed over depth profiles?

How do [salinity, dissolved oxygen, conductivity] change over time for each location? 



## Correlational Analysis

::: {.panel-tabset}

### Clams

#### All Relationships

```{r}
#| echo: false
# Select only numeric columns for correlation analysis
clams_growth_biogeochem_vars_numeric_data <- clams_growth_biogeochem_vars_interp %>%
  select_if(is.numeric) %>% 
  select(-days_btwn_clams_sort)

# Compute the correlation matrix
clams_growth_biogeochem_vars_corr_matrix <- cor(clams_growth_biogeochem_vars_numeric_data)
```

```{r}
#| echo: false
kable(clams_growth_biogeochem_vars_corr_matrix, caption = "KSF Clams Growth and Environmental Variables Correlation Matrix") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

</br>

```{r}
#| echo: false
#| fig-align: center
#| fig-width: 20
#| fig-height: 20
corrplot(clams_growth_biogeochem_vars_corr_matrix, method = "circle",
         tl.cex = 2, # Text label size, change as needed
         tl.col = "black", # Text label color
         tl.srt = 90, # Text label rotation in degrees
         tl.offset = 0.5, 
         cl.pos = "b"
        )
```

#### Specific Relationship

```{r}
#| code-fold: true
#| code-summary: Correlation Between Interpolated Weight and Interpolated Dissolved Oxygen
results <- corr.test(x = clams_growth_biogeochem_vars_interp$clams_count, 
                     y = clams_growth_biogeochem_vars_interp$dissolved_oxygen,
                     method = "pearson", ci = TRUE)

print(results, short=FALSE)
```

```{r}
#| code-fold: true
#| code-summary: Adjusted P-Value
adjusted_p_values <- results$p.adj
print(adjusted_p_values)
```

### Oysters 

#### All Relationships

#### Specific Relationship

:::
