[
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "About",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "index.html#research-questions",
    "href": "index.html#research-questions",
    "title": "About",
    "section": "Research Questions",
    "text": "Research Questions"
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "About",
    "section": "Acknowledgements",
    "text": "Acknowledgements"
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "Unresponsive Shiny Application\n\n\n\nIf the Shiny application fails to load below, please click here.\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data-processing.html",
    "href": "data-processing.html",
    "title": "Data Processing",
    "section": "",
    "text": "Interactive Code\n\n\n\nThroughout this document, hover over the numbered annotations to the right of code chunks to reveal detailed explanations and comments about the code. Where drop-down italicized text is present, expand by pressing on arrow to see code."
  },
  {
    "objectID": "data-processing.html#data-importation",
    "href": "data-processing.html#data-importation",
    "title": "Data Processing",
    "section": "Data Importation",
    "text": "Data Importation\n\nData Sources\n\n\nProcedure\n\n\nStep 1: Efficiently install packages and load libraries\nif (!requireNamespace(\"pacman\", quietly = TRUE)) {\n  install.packages(\"pacman\")\n}\n\npacman::p_load(\n  renv, \n  yaml, \n  rmarkdown, \n  rio, \n  tidyverse, \n  janitor, \n  lubridate, \n  fs,\n  hms, \n  zoo, \n  corrplot, \n  kableExtra, \n  psych, \n  ggplot2, \n  shiny, \n  rsconnect, \n  packrat, \n  plotly, \n  htmlwidgets\n  )\n\n\n\n\nStep 2: Define vector of files to import\ncreate_vector_file_paths &lt;- function(directory_path) {\n  # List all files in the given directory path\n  files_to_import &lt;- fs::dir_ls(path = directory_path)\n  \n  # Loop through the files and print each with an index\n  for (i in seq_along(files_to_import)) {\n    cat(i, \"= \", files_to_import[i], \"\\n\")\n  }\n  \n  # Return the vector of file paths\n  return(files_to_import)\n}\n\nfiles_to_import &lt;- create_vector_file_paths(\"data/raw\")\n\n\n1 =  data/raw/2024-02-28_ksf-clam-growth.xlsx \n2 =  data/raw/2024-02-28_ksf-compiled-data.xlsx \n3 =  data/raw/2024-02-28_ksf-oyster-cylinder-growth.xlsx \n4 =  data/raw/2024-02-28_profile-data.xlsx \n5 =  data/raw/2024-02-28_water-samples.xlsx \n6 =  data/raw/2024-02-28_weather-data.xlsx \n7 =  data/raw/2024-03-18_dfs-no-profiles.RData \n8 =  data/raw/2024-04-09_dfs-no-profiles.RData \n\n\n\n\nStep 3: Only select .xlsx files\nxlsx_files &lt;- files_to_import[str_detect(files_to_import, \".xlsx$\")]\n\n\n\n\nStep 4a: Use the purrr::map() function to iteratively import files in the files_to_import vector except for the profiles data and .RData files\ndfs_no_profiles &lt;- map(xlsx_files, import_list)\ncurrent_date &lt;- format(Sys.Date(), \"%Y-%m-%d\")\nsave(dfs_no_profiles, file = paste0(\"data/raw/\", current_date, \"_dfs-no-profiles.RData\"))\n\n\n\n\n\n\n\n\nStep 4a Execution Warning\n\n\n\nStep 4a should only be ran once when raw data is updated because it takes long to execute. Therefore, do step 4b instead to easily import up-to-date raw data.\n\n\n\n\nStep 4b: Efficiently import up-to-date raw data\nbase::load(files_to_import[8])\n\n\n* We will always use snakecase when naming our data\nobjects and functions (e.g., `data_object_name` or\n`function_name()`).\n\n\nStep 5: Rename datasets\nnames(dfs_no_profiles) &lt;- gsub(\"data/raw/2024-02-28_|\\\\.xlsx$|\\\\.xls$\", \"\", \n1                               xlsx_files)\n2names(dfs_no_profiles) &lt;- gsub(\"-\", \"_\", names(dfs_no_profiles))\n\n\n\n1\n\nRemove prefixes and file extensions\n\n2\n\nReplace hyphens with underscores\n\n\n\n\n\n\nStep 6: Rename each sheet within each raw dataset to be lowercased and replace spaces with underscores\ndfs_no_profiles &lt;- map(dfs_no_profiles, ~ set_names(.x, gsub(\" \", \"_\", tolower(names(.x)))))\n\n\n\n\nStep 7: Create separate datasets by specifying the Excel sheet from each spreadsheet we want to tidy\nksf_clams_growth_data &lt;- dfs_no_profiles$ksf_clam_growth$sheet1\nksf_compiled_data &lt;- dfs_no_profiles$ksf_compiled_data$full_data\nksf_oyster_cylinder_growth_data &lt;- dfs_no_profiles$ksf_oyster_cylinder_growth$sheet1\nwater_samples_data &lt;- dfs_no_profiles$water_samples$data_overview\nweather_data &lt;- dfs_no_profiles$weather_data$weather_ksf\ntidal_data &lt;- dfs_no_profiles$ksf_compiled_data$tides\n\n\n\n\nStep 8: We want to combine multiple sheets within the profiles Excel spreadsheet into one, therefore, we will import it separately\n1sheets_to_import &lt;- c(\"L1\", \"L2\", \"L3\", \"L4\")\n\n2profiles_data &lt;- profiles_data &lt;- map_dfr(sheets_to_import, function(sheet_name) {\n  import(files_to_import[4], which = sheet_name)\n}) %&gt;%\n3  bind_rows()\n\n\n\n1\n\n[code annotation]\n\n2\n\n[code annotation]\n\n3\n\n[code annotation]\n\n\n\n\n\n\nView Raw Data\n\nksf_clams_growth_dataksf_compiled_dataksf_oyster_cylinder_growth_datawater_samples_dataweather_dataprofiles_datatidal_data"
  },
  {
    "objectID": "data-processing.html#data-cleaning-and-preparation",
    "href": "data-processing.html#data-cleaning-and-preparation",
    "title": "Data Processing",
    "section": "Data Cleaning and Preparation",
    "text": "Data Cleaning and Preparation\n\nTidying Raw Datasets\n\nksf_clams_growth_data_tidiedksf_compiled_data_tidiedksf_oyster_cylinder_growth_data_tidiedwater_samples_data_tidiedweather_data_tidiedprofiles_data_tidiedtidal_data_tidied\n\n\n\n\nSteps to clean data\n1new_clam_var_names &lt;- c(\n  \"sort_date\", \"color\", \"clams_in_count\", \"clams_in_lbs\",  \"clams_in_avg_per_lb\",\n  \"clams_out_count\", \"clams_out_lbs\", \"clams_out_avg_per_lb\", \"growth_in_lbs\", \n  \"growth_pct\", \"sr\", \"days_btwn_sort\"\n  )\n\n2new_clam_date_col &lt;- c(\n  \"2023-10-17\", \"2023-12-06\", \"2023-12-12\", \"2024-01-02\",  \"2024-01-10\", \"2024-01-24\",\n  \"2024-01-31\", \"2024-02-08\", \"2024-02-13\", \"2024-03-14\", \"2024-03-19\", \"2024-03-27\"\n  )\n\nksf_clams_growth_data_tidied &lt;- ksf_clams_growth_data %&gt;%\n3  slice(-1) %&gt;%\n4  setNames(new_clam_var_names) %&gt;%\n  mutate(date = as.Date(new_clam_date_col)) %&gt;%\n  dplyr::select(-sort_date) %&gt;%\n   pivot_longer(\n    cols = c(\n      clams_in_count, clams_in_lbs, clams_in_avg_per_lb,   clams_out_count, \n      clams_out_lbs, clams_out_avg_per_lb\n      ),\n    names_to = c(\"stage\", \".value\"),\n    names_prefix = \"clams_\",\n    names_sep = \"_\",\n    values_to = \"value\"\n  ) %&gt;%\n5  mutate(stage = if_else(str_detect(stage, \"in\"), \"In\", \"Out\")) %&gt;%\n6  rename(avg_per_lbs = avg) %&gt;%\n7  mutate(across(c(color, stage), as.factor)) %&gt;%\n8  mutate(across(c(count, lbs, avg_per_lbs, growth_in_lbs, growth_pct, sr),\n                ~as.numeric(gsub(\"%\", \"\", .)))) %&gt;%\n9  arrange(date, color, stage) %&gt;%\n  dplyr::select(date, days_btwn_sort, color, stage, count, lbs, avg_per_lbs,\n                growth_in_lbs, growth_pct, sr) %&gt;%\n  rename(\"days_btwn_clams_sort\" = days_btwn_sort,\n         \"clams_color\" = color,\n         \"clams_stage\" = stage,\n         \"clams_count\" = count,\n         \"weight\" = lbs,\n         \"avg_weight\" = avg_per_lbs,\n         \"clams_growth\" = growth_in_lbs,\n         \"clams_sr\" = sr, \n          \"date_out\" = date\n         ) %&gt;% \n    mutate(date_in = date_out - days_btwn_clams_sort) %&gt;%\nrelocate(c(date_in, date_out), .before = days_btwn_clams_sort) %&gt;% \n  mutate(\n    date = case_when(\n      clams_stage == 'In' ~ date_in,\n      clams_stage == 'Out' ~ date_out\n    )\n  ) %&gt;%\n  select(-date_in, -date_out) %&gt;% \n   mutate(grouping_variable = rep(1:(n() / 2), each = 2))\n\n\npaged_table(ksf_clams_growth_data_tidied)\n\n\n\n1\n\nManually set variable names\n\n2\n\nAssign dates to new date column\n\n3\n\nDelete first row\n\n4\n\nSet date as correct variable type and pivot data set based on date range.\n\n5\n\nAssign In and Out to stage\n\n6\n\nRename variable of average to average per lbs\n\n7\n\nSet stage and color as factor variable types\n\n8\n\nSet variables as numeric variable types\n\n9\n\nArrange values by date, color, and stage\n\n\n\n\n\n  \n\n\n\n\n\n\n\nSteps to clean data\nksf_compiled_data_tidied &lt;- ksf_compiled_data %&gt;% \n1  rename_with(~gsub(\"\\\\s*\\\\([^\\\\)]+\\\\)\", \"\", .x)) %&gt;%\n  janitor::clean_names() %&gt;%\n2  rename(date = date_time) %&gt;%\n  mutate(date = as.Date(date)) %&gt;%\n  filter(date &gt;= as.Date(\"2023-11-20\") & date &lt;= as.Date(\"2024-02-20\")) %&gt;%\n  arrange(date) %&gt;%\n3  dplyr::select(-c(external_voltage, wk_num, wind_dir,\n                   spadd, outdoor_temperature, hourly_rain,\n                   solar_radiation, resistivity, battery_capacity,\n                   hour, daynum, data_pt, wind_sp, diradd,\n                   wind_speed, wind_direction, tide, day, month, year)\n                ) %&gt;%\n4  dplyr::select(where(~ !anyNA(.))) %&gt;%\n5  group_by(date) %&gt;%\n  summarise(across(where(is.numeric), \\(x) mean(x, na.rm = TRUE))) %&gt;%\n  rename(\"ksf_salinity\" = salinity,\n         \"ksf_rdo_saturation\" = rdo_saturation,\n         \"ksf_rdo_concentration\" = rdo_concentration,\n         \"ksf_actual_conductivity\" = actual_conductivity,\n         \"ksf_total_dissolved_solids\" = total_dissolved_solids,\n         \"ksf_ammonium\" = ammonium,\n         \"ksf_barometric_pressure\" = barometric_pressure,\n         \"ksf_oxygen_partial_pressure\" = oxygen_partial_pressure,\n         \"ksf_specific_conductivity\" = specific_conductivity,\n         \"ksf_density\" = density,\n         \"ksf_chlorophyll_a_fluorescence\" = chlorophyll_a_fluorescence,\n         \"ksf_ammonium_m_v\" = ammonium_m_v)\n\npaged_table(ksf_compiled_data_tidied)\n\n\n\n1\n\nClean variable names by removing everything in parentheses, using lowercase and underscores in place of spaces\n\n2\n\nRename the date_time variable to date, filter to desired date range and sort by date\n\n3\n\nRemove unnecessary variables\n\n4\n\nRemove columns with containing all NA values\n\n5\n\nGroup by date and calculate the average of every variable for each day\n\n\n\n\n\n  \n\n\n\n\n\n\n\nSteps to clean data\noyster_var_names &lt;- c(\n  \"date\", \"oyster_large_weight\", \"oyster_large_gain\", \"oyster_small_weight\",\n  \"oyster_small_gain\", \"oyster_chlorophyll\"\n1  )\n\nksf_oyster_cylinder_growth_data_tidied &lt;- ksf_oyster_cylinder_growth_data %&gt;% \n2  dplyr::select(c(1, 4, 5, 8, 9, 12)) %&gt;%\n  slice(-1) %&gt;%\n  setNames(oyster_var_names) %&gt;%\n3  pivot_longer(\n    cols = c(oyster_large_weight, oyster_large_gain,\n             oyster_small_gain,\n             oyster_small_weight),\n    names_to = c(\"oyster_size\", \".value\"),\n    names_prefix = \"oyster_\",\n    names_sep = \"_\",\n    values_to = \"value\"\n  ) %&gt;%\n4  mutate(oyster_size = if_else(str_detect(oyster_size, \"small\"), \"Small\", \"Large\")) %&gt;%\n5  mutate(date = as.Date(date),\n         oyster_size = as.factor(oyster_size),\n         across(c(weight, gain), as.numeric)\n        ) %&gt;%\n6  filter(date &gt;= as.Date(\"2023-11-20\") & date &lt;=\n           as.Date(\"2024-02-20\")) %&gt;%\n  mutate(weight = weight * 0.00220462) %&gt;% \n  rename(\"growth_pct\" = gain) %&gt;%\n  select(-growth_pct) %&gt;% \n  filter(!is.na(weight) & oyster_size != \"Large\")\n\npaged_table(ksf_oyster_cylinder_growth_data_tidied)\n\n\n\n1\n\nManually set variable names\n\n2\n\nSelect desired columns and remove first row\n\n3\n\nConvert from wide to long format\n\n4\n\nCreate a new variable that differentiates oyster size\n\n5\n\nAdjust data types to numeric and factor\n\n6\n\nFilter to desired date range\n\n\n\n\n\n  \n\n\n\n\n\n\n\nSteps to clean data\nwater_samples_data_tidied &lt;- water_samples_data %&gt;%\n  slice(-c(44:52)) %&gt;% \n1  rename_with(~gsub(\"\\\\s*\\\\([^\\\\)]+\\\\)\", \"\", .x)) %&gt;%\n  janitor::clean_names() %&gt;%\n2  mutate(\n    date = if_else(date == \"44074\",\n            as.character(as.Date(\"2024-01-09\")),\n            format(dmy(date), \"%Y-%m-%d\"))\n  ) %&gt;%\n3  mutate(sample_id = 1:nrow(.)) %&gt;%\n4  mutate(date = as.Date(date),\n         across(c(nomilo_id, location, round, depth), as.factor)) %&gt;%\n  select(-c(sample_id, nomilo_id, tube_name)) %&gt;% \n  mutate(location = str_to_title(location)) %&gt;%\n  mutate(location = factor(location, \n                           levels = c(\"Mid Buoy\", \"Back Buoy\", \"Auwei\", \"Production Dock\"))) %&gt;% \n   filter(!is.na(location))\n\npaged_table(water_samples_data_tidied)\n\n\n\n1\n\nClean variable names by removing everything in parentheses, using lowercase and underscores in place of spaces\n\n2\n\nReplaces incorrect date values and format as YYYY-MM-DD\n\n3\n\nAdd values for sample ID\n\n4\n\nSet correct variable types\n\n\n\n\n\n  \n\n\n\n\n\n\n\nSteps to clean data\nweather_data_tidied &lt;- weather_data %&gt;% \n\n1janitor::clean_names() %&gt;%\n2   unite(date, year, month, day, sep = \"-\") %&gt;%\n  mutate(date = ymd(date)) %&gt;%\n3   select(-c(1, 3)) %&gt;%\n4  rename(\"outdoor_temperature\" = outdoor_temp_f) %&gt;%\n   mutate(outdoor_temperature = (outdoor_temperature - 32) * (5/9)) %&gt;%\n5  group_by(date) %&gt;%\n  summarise(across(where(is.numeric), \\(x) mean(x, na.rm = TRUE))) %&gt;%\n6  slice(-1)\n\npaged_table(weather_data_tidied)\n\n\n\n1\n\nClean variable names\n\n2\n\nMerge separate day, month, year columns into one column variable and format as YYYY-MM-DD.\n\n3\n\nCut columns\n\n4\n\nRename outdoor temperature and convert from Fahrenheit to Celcius\n\n5\n\nGroup by date and then take average values per day\n\n6\n\nCut first row\n\n\n\n\n\n  \n\n\n\n\n\n\n\nSteps to clean data\n1new_profile_var_names &lt;- c(\"depth\", \"water_temperature\", \"dissolved_oxygen\", \"salinity\", \"conductivity\", \"visibility\", \"location\", \"date\")\n\n2profiles_data_tidied &lt;- profiles_data %&gt;%\n  select(-c(6, 8)) %&gt;%\n3  mutate(\n    temp_column1 = NA_character_,\n    temp_column2 = NA_character_\n  ) %&gt;%\n4  setNames(new_profile_var_names) %&gt;%\n5  mutate(\n    location = ifelse(depth == \"Location\", water_temperature, NA_character_), \n    date = ifelse(depth == \"Date\",  water_temperature, NA_character_)\n  ) %&gt;%\n6  fill(location, date, .direction = \"down\") %&gt;%\n7  filter(depth != \"Location\", depth != \"Date\") %&gt;%\n8  mutate(\n    location = case_when(\n      location == \"L1 Northwest buoy\" ~ \"back buoy\",\n      location == \"L2 Middle Buoy\" ~ \"mid buoy\",\n      location == \"L3 Production Dock\" ~ \"production dock\",\n      location == \"L4 Auwai\" ~ \"auwei\",\n      TRUE ~ location\n    ),\n    date = case_when(\n      date %in% c(\"45258\", \"2023-11-28\") ~ \"2023-11-28\",\n      date %in% c(\"45282\", \"2023-12-21\") ~ \"2023-12-21\",\n      date %in% c(\"45536\", \"2024-01-09\") ~ \"2024-01-09\",\n      date %in% c(\"30/1/24\", \"30/01/24\") ~ \"2024-01-30\",\n      date %in% c(\"20/02/24\", \"20/2/24\") ~ \"2024-02-20\",\n      TRUE ~ date\n    )) %&gt;%\n  mutate(\n    date = as.Date(date, format = \"%Y-%m-%d\"),\n9     conductivity = case_when(\n      row_number() %in% c(1:11, 53:62, 128:133, 159:161) ~ NA_character_,\n      TRUE ~ as.character(conductivity)\n    )\n  ) %&gt;%\n10  filter(!(depth %in% c(\"Samples\", \"Depth\"))) %&gt;%\n11  mutate(date = as.Date(date),\n         across(c(depth, location), as.factor),\n         across(c(water_temperature,  dissolved_oxygen, salinity, \n                  conductivity,visibility),  as.numeric)) %&gt;%\n12   fill(visibility, .direction = \"down\") %&gt;%\n  mutate(visibility = if_else(date == \"2023-11-28\",  NA_real_, visibility)) %&gt;%\n  mutate(location = str_to_title(location)) %&gt;%\n  mutate(location = factor(location, \n                           levels = c(\"Mid Buoy\", \"Back Buoy\", \"Auwei\", \"Production Dock\"))) %&gt;% \n  mutate(conductivity = coalesce(conductivity, salinity)) %&gt;% \n  rename(\"salinity1\" = salinity,\n         \"salinity\" = conductivity) %&gt;% \n  select(-salinity1)\n\npaged_table(profiles_data_tidied)\n\n\n\n1\n\nSet new variable names manually\n\n2\n\nDelete unnecessary columns\n\n3\n\nTemporarily create two new columns to replace the ones we deleted\n\n4\n\nAssign new profile variable names to rename variables in data set\n\n5\n\nTakes location from one column of location and date data, and assigns it to corresponding data of another column.\n\n6\n\nFill values of temperature downwards in newly created date and location column.\n\n7\n\nGets rid of the ‘location’ and ‘date’ rows that had empty values.\n\n8\n\nRenames values\n\n9\n\nRemoves turbidity data rows 1:11\n\n10\n\nLooks for rows containing samples and depth names and negate these values.\n\n11\n\nSets correct data types for each variable\n\n12\n\nFills values from the temperature downwards into the newly created columns for date and location\n\n\n\n\n\n  \n\n\n\n\n\n\n\nSteps to clean data\ntidal_data_tidied &lt;- tidal_data %&gt;% \n\n1janitor::clean_names() %&gt;%\n2  mutate(date = as.Date(date, format = \"%Y-%m-%d\"))  %&gt;%\n3   filter(date &gt;= as.Date(\"2023-11-20\") & date &lt;=  as.Date(\"2024-02-20\")) %&gt;%\n4  select(-2) %&gt;%\n5  mutate(time = as_hms(format(time, \"%H:%M:%S\")),\n6         high_low = as.factor(high_low))\n  \npaged_table(tidal_data_tidied)\n\n\n\n1\n\nClean variable names\n\n2\n\nSet date as correct variable type and format YYYY-MM-DD\n\n3\n\nFilter to desired date range\n\n4\n\nCut column\n\n5\n\nSet time as time variable type\n\n6\n\nSet variable as factor type"
  },
  {
    "objectID": "data-processing.html#data-exportation",
    "href": "data-processing.html#data-exportation",
    "title": "Data Processing",
    "section": "Data Exportation",
    "text": "Data Exportation\n\nExporting Processed Data\n\n\nExport tidied datasets to CSV into data/tidied folder\nsource(\"code/functions/export_to_csv.R\")\n\n1dfs_to_export &lt;- list(\n  ksf_clams_growth_data_tidied = ksf_clams_growth_data_tidied,\n  # ksf_compiled_data_tidied = ksf_compiled_data_tidied,\n  ksf_oyster_cylinder_growth_data_tidied = ksf_oyster_cylinder_growth_data_tidied\n  # water_samples_data_tidied = water_samples_data_tidied,\n  # profiles_data_tidied = profiles_data_tidied,\n  # biogeochem_vars_merged = biogeochem_vars_merged,\n  # profiles_water_samples_merged = profiles_water_samples_merged,\n  # tidal_data_tidied = tidal_data_tidied,\n  # weather_data_tidied = weather_data_tidied\n  )\n\n2imap(dfs_to_export, ~ export_to_csv(.x, .y, \"data/tidied\"))\n\n\n\n1\n\nList of dataframes we want to export as CSV files\n\n2\n\nIterate the export_to_csv(df, df_name, dir_path) function over each dataframe. .x refers to the dataframe. .y refers to the name of the dataframe. These are passed to export_to_csv() function along with the desired directory path.\n\n\n\n\n\n\nExport merged final data set into data/outputs folder\nexport_to_csv(profiles_data_tidied,\n              \"profiles_data_tidied\",\n              \"data/tidied\")"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "Nomilo Fishpond Biogeochemical Analysis",
    "section": "",
    "text": "Creative Commons Legal Code\nCC0 1.0 Universal\nCREATIVE COMMONS CORPORATION IS NOT A LAW FIRM AND DOES NOT PROVIDE\nLEGAL SERVICES. DISTRIBUTION OF THIS DOCUMENT DOES NOT CREATE AN\nATTORNEY-CLIENT RELATIONSHIP. CREATIVE COMMONS PROVIDES THIS\nINFORMATION ON AN \"AS-IS\" BASIS. CREATIVE COMMONS MAKES NO WARRANTIES\nREGARDING THE USE OF THIS DOCUMENT OR THE INFORMATION OR WORKS\nPROVIDED HEREUNDER, AND DISCLAIMS LIABILITY FOR DAMAGES RESULTING FROM\nTHE USE OF THIS DOCUMENT OR THE INFORMATION OR WORKS PROVIDED\nHEREUNDER.\nStatement of Purpose\nThe laws of most jurisdictions throughout the world automatically confer exclusive Copyright and Related Rights (defined below) upon the creator and subsequent owner(s) (each and all, an “owner”) of an original work of authorship and/or a database (each, a “Work”).\nCertain owners wish to permanently relinquish those rights to a Work for the purpose of contributing to a commons of creative, cultural and scientific works (“Commons”) that the public can reliably and without fear of later claims of infringement build upon, modify, incorporate in other works, reuse and redistribute as freely as possible in any form whatsoever and for any purposes, including without limitation commercial purposes. These owners may contribute to the Commons to promote the ideal of a free culture and the further production of creative, cultural and scientific works, or to gain reputation or greater distribution for their Work in part through the use and efforts of others.\nFor these and/or other purposes and motivations, and without any expectation of additional consideration or compensation, the person associating CC0 with a Work (the “Affirmer”), to the extent that he or she is an owner of Copyright and Related Rights in the Work, voluntarily elects to apply CC0 to the Work and publicly distribute the Work under its terms, with knowledge of his or her Copyright and Related Rights in the Work and the meaning and intended legal effect of CC0 on those rights.\n\nCopyright and Related Rights. A Work made available under CC0 may be protected by copyright and related or neighboring rights (“Copyright and Related Rights”). Copyright and Related Rights include, but are not limited to, the following:\n\n\nthe right to reproduce, adapt, distribute, perform, display, communicate, and translate a Work;\nmoral rights retained by the original author(s) and/or performer(s);\npublicity and privacy rights pertaining to a person’s image or likeness depicted in a Work;\nrights protecting against unfair competition in regards to a Work, subject to the limitations in paragraph 4(a), below;\nrights protecting the extraction, dissemination, use and reuse of data in a Work;\ndatabase rights (such as those arising under Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, and under any national implementation thereof, including any amended or successor version of such directive); and\nother similar, equivalent or corresponding rights throughout the world based on applicable law or treaty, and any national implementations thereof.\n\n\nWaiver. To the greatest extent permitted by, but not in contravention of, applicable law, Affirmer hereby overtly, fully, permanently, irrevocably and unconditionally waives, abandons, and surrenders all of Affirmer’s Copyright and Related Rights and associated claims and causes of action, whether now known or unknown (including existing as well as future claims and causes of action), in the Work (i) in all territories worldwide, (ii) for the maximum duration provided by applicable law or treaty (including future time extensions), (iii) in any current or future medium and for any number of copies, and (iv) for any purpose whatsoever, including without limitation commercial, advertising or promotional purposes (the “Waiver”). Affirmer makes the Waiver for the benefit of each member of the public at large and to the detriment of Affirmer’s heirs and successors, fully intending that such Waiver shall not be subject to revocation, rescission, cancellation, termination, or any other legal or equitable action to disrupt the quiet enjoyment of the Work by the public as contemplated by Affirmer’s express Statement of Purpose.\nPublic License Fallback. Should any part of the Waiver for any reason be judged legally invalid or ineffective under applicable law, then the Waiver shall be preserved to the maximum extent permitted taking into account Affirmer’s express Statement of Purpose. In addition, to the extent the Waiver is so judged Affirmer hereby grants to each affected person a royalty-free, non transferable, non sublicensable, non exclusive, irrevocable and unconditional license to exercise Affirmer’s Copyright and Related Rights in the Work (i) in all territories worldwide, (ii) for the maximum duration provided by applicable law or treaty (including future time extensions), (iii) in any current or future medium and for any number of copies, and (iv) for any purpose whatsoever, including without limitation commercial, advertising or promotional purposes (the “License”). The License shall be deemed effective as of the date CC0 was applied by Affirmer to the Work. Should any part of the License for any reason be judged legally invalid or ineffective under applicable law, such partial invalidity or ineffectiveness shall not invalidate the remainder of the License, and in such case Affirmer hereby affirms that he or she will not (i) exercise any of his or her remaining Copyright and Related Rights in the Work or (ii) assert any associated claims and causes of action with respect to the Work, in either case contrary to Affirmer’s express Statement of Purpose.\nLimitations and Disclaimers.\n\n\nNo trademark or patent rights held by Affirmer are waived, abandoned, surrendered, licensed or otherwise affected by this document.\nAffirmer offers the Work as-is and makes no representations or warranties of any kind concerning the Work, express, implied, statutory or otherwise, including without limitation warranties of title, merchantability, fitness for a particular purpose, non infringement, or the absence of latent or other defects, accuracy, or the present or absence of errors, whether or not discoverable, all to the greatest extent permissible under applicable law.\nAffirmer disclaims responsibility for clearing rights of other persons that may apply to the Work or any use thereof, including without limitation any person’s Copyright and Related Rights in the Work. Further, Affirmer disclaims responsibility for obtaining any necessary consents, permissions or other rights required for any use of the Work.\nAffirmer understands and acknowledges that Creative Commons is not a party to this document and has no duty or obligation with respect to this CC0 or use of the Work.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data-collection.html",
    "href": "data-collection.html",
    "title": "Data Collection App",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "correlational-analysis.html",
    "href": "correlational-analysis.html",
    "title": "Correlational Analysis",
    "section": "",
    "text": "library(here)\nlibrary(tidyverse)\nlibrary(psych)\nsource(here(\"code/functions/create_vector_file_paths.R\"))\nfiles_to_import &lt;- create_vector_file_paths(here(\"data/output\"))\n\n1 =  /Users/lysbethkoster/Documents/Universiteit/University of Hawai'i/MSc Thesis/Thesis/RQ2/nomilo-fishpond-analysis/data/output/2024-03-15_ksf-compiled-data-final.csv \n2 =  /Users/lysbethkoster/Documents/Universiteit/University of Hawai'i/MSc Thesis/Thesis/RQ2/nomilo-fishpond-analysis/data/output/2024-03-15_water-samples-data-final.csv \n3 =  /Users/lysbethkoster/Documents/Universiteit/University of Hawai'i/MSc Thesis/Thesis/RQ2/nomilo-fishpond-analysis/data/output/2024-03-20_weather-data-final.csv \n4 =  /Users/lysbethkoster/Documents/Universiteit/University of Hawai'i/MSc Thesis/Thesis/RQ2/nomilo-fishpond-analysis/data/output/2024-04-09_ksf-clams-growth-data-final.csv \n5 =  /Users/lysbethkoster/Documents/Universiteit/University of Hawai'i/MSc Thesis/Thesis/RQ2/nomilo-fishpond-analysis/data/output/2024-04-09_ksf-oyster-cylinder-growth-data-final.csv \n6 =  /Users/lysbethkoster/Documents/Universiteit/University of Hawai'i/MSc Thesis/Thesis/RQ2/nomilo-fishpond-analysis/data/output/2024-04-09_profiles-data-final.csv \n\n# Preload data\ndfs &lt;- list(\n  \"water_samples\" = readr::read_csv(files_to_import[2]),\n  \"profiles\" = readr::read_csv(files_to_import[6]),\n  \"clams_growth\" = readr::read_csv(files_to_import[4]),\n  \"oyster_growth\" = readr::read_csv(files_to_import[5]),\n  \"weather\" = readr::read_csv(files_to_import[3]),\n  \"ksf_compiled\" = readr::read_csv(files_to_import[1])\n)"
  },
  {
    "objectID": "correlational-analysis.html#instrument-validation",
    "href": "correlational-analysis.html#instrument-validation",
    "title": "Correlational Analysis",
    "section": "Instrument Validation",
    "text": "Instrument Validation\n\nConductivity & Dissolved Oxygen \n\n\nCorrelation Between KSF Oxygen Partial Pressure and Collected Dissolved Oxygen on Specific Days at a 0.5 Depth at the Production Dock\nfiltered_dates &lt;- c(\"2023-11-28\", \"2023-12-21\", \"2024-01-09\", \"2024-01-30\", \"2024-02-20\") \nksf_compiled_filtered_dates &lt;- dfs$ksf_compiled %&gt;% \n  filter(date %in% filtered_dates) \n\nwater_profiles_filtered_location &lt;- dfs$profiles %&gt;% \n  filter(location == \"Production Dock\" & depth == 0.5)\n\nresults &lt;- corr.test(x = ksf_compiled_filtered_dates$ksf_salinity, \n                     y = water_profiles_filtered_location$salinity,\n                     method = \"pearson\", ci = TRUE)\n\nprint(results, short=FALSE)\n\n\nCall:corr.test(x = ksf_compiled_filtered_dates$ksf_salinity, y = water_profiles_filtered_location$salinity, \n    method = \"pearson\", ci = TRUE)\nCorrelation matrix \n[1] -0.41\nSample Size \n[1] 5\nThese are the unadjusted probability values.\n  The probability values  adjusted for multiple tests are in the p.adj object. \n[1] 0.49\n\n Confidence intervals based upon normal theory.  To get bootstrapped values, try cor.ci\n      raw.lower raw.r raw.upper raw.p lower.adj upper.adj\nNA-NA     -0.95 -0.41      0.74  0.49     -0.95      0.74\n\n\n\n\nHypothesis Testing\nH1. Increase in phytoplankton production positively correlates with higher dissolved oxygen.\n\nwater_profiles_filtered_location &lt;- dfs$profiles %&gt;% \n  filter(location == \"Mid Buoy\" & depth == 0.5)\n\nwater_samples_filtered_location &lt;- dfs$water_samples %&gt;% \n  filter(location == \"Mid Buoy\" & depth == 0.5)\n\nresults &lt;- corr.test(x = water_samples_filtered_location$large_phytoplankton, \n                     y = water_profiles_filtered_location$dissolved_oxygen,\n                     method = \"pearson\", ci = TRUE)\n\nprint(results, short=FALSE)\n\nCall:corr.test(x = water_samples_filtered_location$large_phytoplankton, \n    y = water_profiles_filtered_location$dissolved_oxygen, method = \"pearson\", \n    ci = TRUE)\nCorrelation matrix \n[1] 0.8\nSample Size \n[1] 4\nThese are the unadjusted probability values.\n  The probability values  adjusted for multiple tests are in the p.adj object. \n[1] 0.2\n\n Confidence intervals based upon normal theory.  To get bootstrapped values, try cor.ci\n      raw.lower raw.r raw.upper raw.p lower.adj upper.adj\nNA-NA     -0.69   0.8         1   0.2     -0.69         1\n\n\nAH1: Increase in cyanobacteria production correlates with lower dissolved oxygen levels in the water column.\n\nwater_profiles_filtered_location &lt;- dfs$profiles %&gt;% \n  filter(location == \"Mid Buoy\" & depth == 0.5)\n\nwater_samples_filtered_location &lt;- dfs$water_samples %&gt;% \n  filter(location == \"Mid Buoy\" & depth == 0.5) %&gt;% \n  select(c(synechococcus_population_1, synechococcus_population_2))\n\nresults &lt;- corr.test(x = water_samples_filtered_location, \n                     y = water_profiles_filtered_location$dissolved_oxygen,\n                     method = \"pearson\", ci = TRUE)\n\nprint(results, short=FALSE)\n\nCall:corr.test(x = water_samples_filtered_location, y = water_profiles_filtered_location$dissolved_oxygen, \n    method = \"pearson\", ci = TRUE)\nCorrelation matrix \n                            [,1]\nsynechococcus_population_1 -0.86\nsynechococcus_population_2 -0.72\nSample Size \n[1] 4\nThese are the unadjusted probability values.\n  The probability values  adjusted for multiple tests are in the p.adj object. \n                           [,1]\nsynechococcus_population_1 0.14\nsynechococcus_population_2 0.28\n\n Confidence intervals based upon normal theory.  To get bootstrapped values, try cor.ci\n         raw.lower raw.r raw.upper raw.p lower.adj upper.adj\nsy__1-NA     -1.00 -0.86      0.57  0.14     -1.00      0.73\nsy__2-NA     -0.99 -0.72      0.78  0.28     -0.99      0.78\n\n\n::: {.panel-tabset}\nH3: Higher nutrient availability positively correlates with chlorophyll production (total nitrogen, total phosphorus, and N:P ratio).\n\ncor.test(dfs$water_samples$phosphate, dfs$water_samples$chlorophyll_a)\n\n\n    Pearson's product-moment correlation\n\ndata:  dfs$water_samples$phosphate and dfs$water_samples$chlorophyll_a\nt = 1.3192, df = 31, p-value = 0.1967\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.1224407  0.5317770\nsample estimates:\n      cor \n0.2305599 \n\n\nH4: Strong western winds positively correlate with chlorophyll production.\n\nfiltered_dates &lt;- c(\"2023-11-28\", \"2023-12-21\", \"2024-01-09\", \"2024-01-30\", \"2024-02-20\")\n\nweather_filter_dates &lt;- dfs$weather %&gt;% \n  filter(date %in% filtered_dates) \n\nwater_samples_filtered_location &lt;- dfs$water_samples %&gt;% \n  filter(location == \"Back Buoy\" & depth == 0.5)\n\ncor.test(weather_filter_dates$wind_direction, water_samples_filtered_location$chlorophyll_a)\n\n\n    Pearson's product-moment correlation\n\ndata:  weather_filter_dates$wind_direction and water_samples_filtered_location$chlorophyll_a\nt = -1.4293, df = 2, p-value = 0.2892\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9933152  0.7898645\nsample estimates:\n       cor \n-0.7108463"
  }
]